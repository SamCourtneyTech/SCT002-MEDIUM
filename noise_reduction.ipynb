{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 361\n",
      "True True\n",
      "['clean_fileid_223.wav', 'clean_fileid_237.wav'] ['p300_014_mic1_seg1-p316_209_mic1_seg1-p272_029_mic1_seg1-p287_091_mic2_seg1_BatGg1Wwhz4_snr-1_tl-33_fileid_124.wav', 'p335_016_mic1_seg1-p297_005_mic1_seg1_bnCiy9pQbHM_snr-3_tl-29_fileid_341.wav']\n",
      "361 361\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths to audio files\n",
    "clean_path = \"/Users/samcourtney/Downloads/DNS-Challenge/clean_output\"\n",
    "noisy_path = \"/Users/samcourtney/Downloads/DNS-Challenge/noisy_output\"\n",
    "\n",
    "# Load audio files\n",
    "clean_files = [os.path.join(clean_path, f) for f in os.listdir(clean_path)]\n",
    "noisy_files = [os.path.join(noisy_path, f) for f in os.listdir(noisy_path)]\n",
    "\n",
    "# Load one pair to test\n",
    "clean_audio, sr = librosa.load(clean_files[0], sr=16000)  # 16kHz sample rate\n",
    "noisy_audio, _ = librosa.load(noisy_files[0], sr=16000)\n",
    "\n",
    "print(len(clean_files), len(noisy_files))\n",
    "\n",
    "print(os.path.exists(clean_path), os.path.exists(noisy_path))\n",
    "print(os.listdir(clean_path)[:2], os.listdir(noisy_path)[:2])\n",
    "print(len(clean_files), len(noisy_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3603088e-09 0.15945539 0.0029164453\n"
     ]
    }
   ],
   "source": [
    "print(pred[0].min(), pred[0].max(), pred[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute STFT\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "clean_spec = np.abs(librosa.stft(clean_audio, n_fft=n_fft, hop_length=hop_length))\n",
    "noisy_spec = np.abs(librosa.stft(noisy_audio, n_fft=n_fft, hop_length=hop_length))\n",
    "\n",
    "# Normalize spectrograms by maximum only (preserve magnitude scale)\n",
    "clean_spec = clean_spec / (np.max(clean_spec) + 1e-10)\n",
    "noisy_spec = noisy_spec / (np.max(noisy_spec) + 1e-10)\n",
    "\n",
    "# Check shapes\n",
    "print(clean_spec.shape, noisy_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.010091137\n",
      "0.0 1.0 0.0066029755\n"
     ]
    }
   ],
   "source": [
    "# Normalization of spectrograms\n",
    "X_train, y_train = [], []\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "\n",
    "for clean_file, noisy_file in zip(clean_files, noisy_files):\n",
    "    clean_audio, _ = librosa.load(clean_file, sr=16000)\n",
    "    noisy_audio, _ = librosa.load(noisy_file, sr=16000)\n",
    "    clean_spec = np.abs(librosa.stft(clean_audio, n_fft=n_fft, hop_length=hop_length))\n",
    "    noisy_spec = np.abs(librosa.stft(noisy_audio, n_fft=n_fft, hop_length=hop_length))\n",
    "    # Scale to max 1.0 without shifting min\n",
    "    clean_spec = clean_spec / (np.max(clean_spec) + 1e-10)\n",
    "    noisy_spec = noisy_spec / (np.max(noisy_spec) + 1e-10)\n",
    "    X_train.append(noisy_spec[..., np.newaxis])\n",
    "    y_train.append(clean_spec[..., np.newaxis])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(X_train.min(), X_train.max(), X_train.mean())\n",
    "print(y_train.min(), y_train.max(), y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 257, 1251, 1) (36, 257, 1251, 1) (37, 257, 1251, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train (80%), validation (10%), test (10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check shapes\n",
    "print(X_train.shape, X_val.shape, X_test.shape)  # Expected: ~288, ~36, ~36 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1251</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">626</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">626</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">313</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">313</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">626</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">626</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1252</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1252</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cropping2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cropping2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1251</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m, \u001b[38;5;34m1251\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m626\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m626\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m313\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m313\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_12 (\u001b[38;5;33mUpSampling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m626\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m626\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_13 (\u001b[38;5;33mUpSampling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m1252\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m1252\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │           \u001b[38;5;34m289\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cropping2d_5 (\u001b[38;5;33mCropping2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m, \u001b[38;5;34m1251\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,497</span> (291.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,497\u001b[0m (291.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,497</span> (291.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m74,497\u001b[0m (291.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(257, 1251, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'),\n",
    "    layers.Cropping2D(((1, 2), (0, 1)))  # Adjusted to get 257x1251\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 0.2416 - val_loss: 0.2311\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - loss: 0.2237 - val_loss: 0.1884\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - loss: 0.1665 - val_loss: 0.0818\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4s/step - loss: 0.0558 - val_loss: 0.0075\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 4s/step - loss: 9.9907e-04 - val_loss: 9.7232e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - loss: 9.5340e-04 - val_loss: 9.3794e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - loss: 9.2343e-04 - val_loss: 9.1651e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - loss: 8.9918e-04 - val_loss: 9.0292e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - loss: 8.9500e-04 - val_loss: 8.9387e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.9701e-04 - val_loss: 8.8759e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 8.9854e-04 - val_loss: 8.8310e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - loss: 8.6422e-04 - val_loss: 8.7978e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - loss: 8.6142e-04 - val_loss: 8.7723e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - loss: 8.7286e-04 - val_loss: 8.7523e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - loss: 8.4885e-04 - val_loss: 8.7361e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - loss: 8.7145e-04 - val_loss: 8.7230e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - loss: 8.8756e-04 - val_loss: 8.7121e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 8.5944e-04 - val_loss: 8.7027e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - loss: 8.7069e-04 - val_loss: 8.6948e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - loss: 8.6454e-04 - val_loss: 8.6878e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 41s/step - loss: 8.5106e-04 - val_loss: 8.6817e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 5s/step - loss: 8.4666e-04 - val_loss: 8.6764e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - loss: 8.6864e-04 - val_loss: 8.6716e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - loss: 8.6659e-04 - val_loss: 8.6672e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - loss: 8.6422e-04 - val_loss: 8.6633e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - loss: 8.7897e-04 - val_loss: 8.6597e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - loss: 8.5750e-04 - val_loss: 8.6564e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - loss: 8.9225e-04 - val_loss: 8.6534e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - loss: 8.5217e-04 - val_loss: 8.6506e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5s/step - loss: 8.5761e-04 - val_loss: 8.6480e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 5s/step - loss: 8.6864e-04 - val_loss: 8.6456e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - loss: 9.0834e-04 - val_loss: 8.6433e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - loss: 8.6216e-04 - val_loss: 8.6411e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - loss: 8.8176e-04 - val_loss: 8.6391e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - loss: 8.5527e-04 - val_loss: 8.6372e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - loss: 8.5483e-04 - val_loss: 8.6350e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - loss: 8.5400e-04 - val_loss: 8.6329e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 5s/step - loss: 8.5701e-04 - val_loss: 8.6310e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5s/step - loss: 8.6468e-04 - val_loss: 8.6291e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 5s/step - loss: 8.7896e-04 - val_loss: 8.6273e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - loss: 8.6689e-04 - val_loss: 8.6254e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - loss: 8.7030e-04 - val_loss: 8.6236e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - loss: 8.5265e-04 - val_loss: 8.6217e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - loss: 8.7689e-04 - val_loss: 8.6198e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - loss: 8.5339e-04 - val_loss: 8.6180e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - loss: 8.4891e-04 - val_loss: 8.6161e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - loss: 8.7228e-04 - val_loss: 8.6142e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - loss: 8.3700e-04 - val_loss: 8.6123e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - loss: 8.8291e-04 - val_loss: 8.6102e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - loss: 8.5400e-04 - val_loss: 8.6081e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - loss: 8.5352e-04 - val_loss: 8.6060e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.5474e-04 - val_loss: 8.6037e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 8.4064e-04 - val_loss: 8.6015e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 8.4222e-04 - val_loss: 8.5991e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 8.2171e-04 - val_loss: 8.5966e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - loss: 8.8288e-04 - val_loss: 8.5941e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.5293e-04 - val_loss: 8.5916e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.5409e-04 - val_loss: 8.5890e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.5235e-04 - val_loss: 8.5864e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.3198e-04 - val_loss: 8.5837e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - loss: 8.7524e-04 - val_loss: 8.5810e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.7541e-04 - val_loss: 8.5782e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.8566e-04 - val_loss: 8.5754e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.6417e-04 - val_loss: 8.5726e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.6967e-04 - val_loss: 8.5698e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.1749e-04 - val_loss: 8.5669e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.6527e-04 - val_loss: 8.5641e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - loss: 8.2838e-04 - val_loss: 8.5613e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - loss: 8.5922e-04 - val_loss: 8.5585e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - loss: 8.5292e-04 - val_loss: 8.5558e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - loss: 8.2286e-04 - val_loss: 8.5532e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - loss: 8.6544e-04 - val_loss: 8.5505e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - loss: 8.5750e-04 - val_loss: 8.5480e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - loss: 8.2156e-04 - val_loss: 8.5455e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - loss: 8.3503e-04 - val_loss: 8.5432e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - loss: 8.5683e-04 - val_loss: 8.5410e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 5s/step - loss: 8.3618e-04 - val_loss: 8.5386e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 5s/step - loss: 8.3749e-04 - val_loss: 8.5364e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - loss: 8.6836e-04 - val_loss: 8.5342e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - loss: 8.5444e-04 - val_loss: 8.5321e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - loss: 8.6956e-04 - val_loss: 8.5299e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - loss: 8.5289e-04 - val_loss: 8.5276e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 11s/step - loss: 8.3780e-04 - val_loss: 8.5253e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 6s/step - loss: 8.5203e-04 - val_loss: 8.5229e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - loss: 8.5698e-04 - val_loss: 8.5204e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - loss: 8.3532e-04 - val_loss: 8.5178e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - loss: 8.3314e-04 - val_loss: 8.5150e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.3896e-04 - val_loss: 8.5121e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 4s/step - loss: 8.4896e-04 - val_loss: 8.5089e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4s/step - loss: 8.2282e-04 - val_loss: 8.5056e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 4s/step - loss: 8.5396e-04 - val_loss: 8.5019e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.4932e-04 - val_loss: 8.4979e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4s/step - loss: 8.6099e-04 - val_loss: 8.4934e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 8.8084e-04 - val_loss: 8.4885e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - loss: 8.3395e-04 - val_loss: 8.4831e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - loss: 8.0296e-04 - val_loss: 8.4771e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - loss: 8.1940e-04 - val_loss: 8.4700e-04\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    verbose=1,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)]\n",
    ")\n",
    "model.save('noise_reduction_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('noise_reduction_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - loss: 8.9039e-04\n",
      "Test loss: 0.000880122184753418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "2.3603088e-09 0.15945539 0.0029164453\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "pred = model.predict(X_test[:1])\n",
    "print(pred[0].min(), pred[0].max(), pred[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted spectrogram to audio with proper phase information\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Get the original noisy audio for phase information\n",
    "noisy_audio_for_phase, _ = librosa.load(noisy_files[0], sr=16000)\n",
    "\n",
    "# Get complex STFT (with phase) from original noisy audio\n",
    "noisy_stft = librosa.stft(noisy_audio_for_phase, hop_length=128, n_fft=512)\n",
    "noisy_phase = np.angle(noisy_stft)\n",
    "\n",
    "# Use predicted magnitude with original phase\n",
    "pred_spec = pred[0][:, :, 0]\n",
    "pred_spec = pred_spec * np.max(np.abs(noisy_stft))  # Restore original scale\n",
    "pred_complex = pred_spec * np.exp(1j * noisy_phase)  # Combine magnitude and phase\n",
    "pred_audio = librosa.istft(pred_complex, hop_length=128, n_fft=512)\n",
    "sf.write('pred_audio.wav', pred_audio, 16000)\n",
    "\n",
    "# For comparison, also reconstruct test audio properly\n",
    "test_spec = X_test[0][:, :, 0] * np.max(np.abs(noisy_stft))\n",
    "test_complex = test_spec * np.exp(1j * noisy_phase)\n",
    "test_audio = librosa.istft(test_complex, hop_length=128, n_fft=512)\n",
    "sf.write('test_audio.wav', test_audio, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3603088e-09 0.15945539 0.0029164453\n"
     ]
    }
   ],
   "source": [
    "print(pred[0].min(), pred[0].max(), pred[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.010082202\n",
      "0.0 1.0 0.0065916996\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min(), X_train.max(), X_train.mean())\n",
    "print(y_train.min(), y_train.max(), y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - loss: 8.9039e-04\n",
      "Test loss: 0.000880122184753418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "2.3603088e-09 0.15945539 0.0029164453\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "pred = model.predict(X_test[:1])\n",
    "print(pred[0].min(), pred[0].max(), pred[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - loss: 8.9039e-04\n",
      "Test loss: 0.000880122184753418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "2.3603088e-09 0.15945539 0.0029164453\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "pred = model.predict(X_test[:1])\n",
    "print(pred[0].min(), pred[0].max(), pred[0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Load one original clean audio\n",
    "clean_audio, sr = librosa.load(clean_files[0], sr=16000)\n",
    "sf.write('original_clean.wav', clean_audio, 16000)\n",
    "\n",
    "# Convert to spectrogram and back with proper phase preservation\n",
    "clean_stft = librosa.stft(clean_audio, n_fft=512, hop_length=128)\n",
    "clean_spec = np.abs(clean_stft)\n",
    "clean_spec = clean_spec / (np.max(clean_spec) + 1e-10)  # Normalize by max only\n",
    "clean_phase = np.angle(clean_stft)\n",
    "clean_complex = clean_spec * np.max(np.abs(clean_stft)) * np.exp(1j * clean_phase)\n",
    "recon_audio = librosa.istft(clean_complex, hop_length=128, n_fft=512)\n",
    "sf.write('reconstructed_clean.wav', recon_audio, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test audio amplitude levels\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Load original audio and check levels\n",
    "clean_audio, sr = librosa.load(clean_files[0], sr=16000)\n",
    "print(f\"Original clean audio - min: {clean_audio.min():.6f}, max: {clean_audio.max():.6f}, RMS: {np.sqrt(np.mean(clean_audio**2)):.6f}\")\n",
    "\n",
    "# Test simple spectrogram -> audio conversion\n",
    "clean_stft = librosa.stft(clean_audio, n_fft=512, hop_length=128)\n",
    "reconstructed_audio = librosa.istft(clean_stft, hop_length=128, n_fft=512)\n",
    "print(f\"Simple reconstruction - min: {reconstructed_audio.min():.6f}, max: {reconstructed_audio.max():.6f}, RMS: {np.sqrt(np.mean(reconstructed_audio**2)):.6f}\")\n",
    "\n",
    "# Save both for comparison\n",
    "sf.write('original_clean.wav', clean_audio, 16000)\n",
    "sf.write('simple_reconstruction.wav', reconstructed_audio, 16000)\n",
    "\n",
    "# Now test with normalization/denormalization\n",
    "clean_spec = np.abs(clean_stft)\n",
    "original_max = np.max(clean_spec)\n",
    "normalized_spec = clean_spec / (original_max + 1e-10)\n",
    "denormalized_spec = normalized_spec * original_max\n",
    "clean_phase = np.angle(clean_stft)\n",
    "final_complex = denormalized_spec * np.exp(1j * clean_phase)\n",
    "final_audio = librosa.istft(final_complex, hop_length=128, n_fft=512)\n",
    "print(f\"Normalized reconstruction - min: {final_audio.min():.6f}, max: {final_audio.max():.6f}, RMS: {np.sqrt(np.mean(final_audio**2)):.6f}\")\n",
    "sf.write('normalized_reconstruction.wav', final_audio, 16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
